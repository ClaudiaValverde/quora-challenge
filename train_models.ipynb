{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVwnS93T30n-"
   },
   "source": [
    "# Train Models\n",
    "<div style=\"background-color: lightblue; padding: 10px; border-radius: 10px;\">\n",
    "\n",
    "**IMPORTANT INFO:**\n",
    "\n",
    "The `train_models.ipynb` notebook:\n",
    "- Is a responsability of all members of a group. All of you should execute this and ensure it works as expected.\n",
    "- Has to use the code done by each member in the group to generate features for the challenge.\n",
    "\n",
    "\n",
    "`models`: A folder containing the trained models. This folder should be cre- ated by `train_models.ipynb` and models should be stored there after running `train_models.ipynb` notebook. The code should check if the folder is there and in such a case do not overwrite/store the models.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_fFMZVYSjsx"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JoW1tYx-R943"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9cUIGQH4Gku"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkWWR7NwR-2W"
   },
   "source": [
    "From the problem guide the teacher says:\n",
    "\n",
    "This is a Kaggle challenge: There is no validation/test data with labels.\n",
    "Therefore you have to create the following split in order to share the same train validation and test splits across teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HBPAHqjdR2il"
   },
   "outputs": [],
   "source": [
    "path_folder_quora = '../nlp_deliv1_materials/'\n",
    "\n",
    "# Train and Validation data\n",
    "train_df = pd.read_csv(os.path.join(path_folder_quora, \"quora_train_data.csv\"))\n",
    "# use this to provide the expected generalization results\n",
    "test_df = pd.read_csv(os.path.join(path_folder_quora,\"quora_test_data.csv\"))\n",
    "\n",
    "A_df, te_df = sklearn.model_selection.train_test_split(train_df, test_size=0.05, random_state=123)\n",
    "tr_df, va_df = sklearn.model_selection.train_test_split(A_df, test_size=0.05, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1713111794742,
     "user": {
      "displayName": "Clàudia Valverde Sanchez",
      "userId": "17089465752638224867"
     },
     "user_tz": -120
    },
    "id": "ae2vT4FH-4Gw",
    "outputId": "e9c60cc8-5d67-43b1-d1c9-77dd6c3f6d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      " X train (291897, 5)\n",
      " y train (291897,)\n",
      " --------------------\n",
      "Validation:\n",
      " X val (15363, 5)\n",
      " y val (15363,)\n",
      " --------------------\n",
      "Test:\n",
      " X test (16172, 5)\n",
      " y test (16172,)\n",
      " --------------------\n"
     ]
    }
   ],
   "source": [
    "# dividng X and y for each dataset\n",
    "y_tr = tr_df['is_duplicate'].values\n",
    "X_tr_df = tr_df.drop(['is_duplicate'], axis =1)\n",
    "\n",
    "y_va = va_df['is_duplicate'].values\n",
    "X_va_df = va_df.drop(['is_duplicate'], axis =1)\n",
    "\n",
    "y_te = te_df['is_duplicate'].values\n",
    "X_te_df = te_df.drop(['is_duplicate'], axis =1)\n",
    "\n",
    "print(f'Training:\\n X train {X_tr_df.shape}\\n y train {y_tr.shape}\\n {\"-\"*20}')\n",
    "print(f'Validation:\\n X val {X_va_df.shape}\\n y val {y_va.shape}\\n {\"-\"*20}')\n",
    "print(f'Test:\\n X test {X_te_df.shape}\\n y test {y_te.shape}\\n {\"-\"*20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za89utw14LAP"
   },
   "source": [
    "# Simple Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z1CLM54X4Vwp"
   },
   "outputs": [],
   "source": [
    "# convert input data into list of strings\n",
    "\n",
    "q1_train =  cast_list_as_strings(list(X_tr_df[\"question1\"]))\n",
    "q2_train =  cast_list_as_strings(list(X_tr_df[\"question2\"]))\n",
    "\n",
    "q1_val =  cast_list_as_strings(list(X_va_df[\"question1\"]))\n",
    "q2_val =  cast_list_as_strings(list(X_va_df[\"question2\"]))\n",
    "\n",
    "q1_test =  cast_list_as_strings(list(X_te_df[\"question1\"]))\n",
    "q2_test =  cast_list_as_strings(list(X_te_df[\"question2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFsPvvQbNwqW"
   },
   "source": [
    "Use all the questions in train and test partitions to build a single list all_questions to fit the count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 8830,
     "status": "ok",
     "timestamp": 1713111804161,
     "user": {
      "displayName": "Clàudia Valverde Sanchez",
      "userId": "17089465752638224867"
     },
     "user_tz": -120
    },
    "id": "Ws2nWF8-MdwI",
    "outputId": "94761172-bfc1-479c-d674-7d0e5b409ec1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_q_train = q1_train+q2_train\n",
    "\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer.fit(all_q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "57sFuKVxNVnM"
   },
   "outputs": [],
   "source": [
    "# get features (concatenating q1+q2)\n",
    "X_tr_q1q2 = get_features_from_df(X_tr_df, count_vectorizer) # it converts list as strings and performs count_vectorizer\n",
    "X_va_q1q2 = get_features_from_df(X_va_df, count_vectorizer)\n",
    "X_te_q1q2 = get_features_from_df(X_te_df, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1713111814432,
     "user": {
      "displayName": "Clàudia Valverde Sanchez",
      "userId": "17089465752638224867"
     },
     "user_tz": -120
    },
    "id": "x9raLtLDV4fU",
    "outputId": "a0b0755e-1558-4f08-a557-08b18ae1885d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      " X train (291897, 149650)\n",
      " --------------------\n",
      "Validation:\n",
      " X val (15363, 149650)\n",
      "--------------------\n",
      "Test:\n",
      " X test (16172, 149650)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Training:\\n X train {X_tr_q1q2.shape}\\n {\"-\"*20}')\n",
    "print(f'Validation:\\n X val {X_va_q1q2.shape}\\n{\"-\"*20}')\n",
    "print(f'Test:\\n X test {X_te_q1q2.shape}\\n{\"-\"*20}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 119476,
     "status": "ok",
     "timestamp": 1713111933902,
     "user": {
      "displayName": "Clàudia Valverde Sanchez",
      "userId": "17089465752638224867"
     },
     "user_tz": -120
    },
    "id": "O1-7XogxV7WV",
    "outputId": "509cb760-583c-4fe5-b9c6-311216ca1432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=123, solver='liblinear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training a simple model\n",
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",\n",
    "                                                   random_state=123)\n",
    "y_train = train_df[\"is_duplicate\"].values\n",
    "logistic.fit(X_tr_q1q2, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTbjV4FR9iSc"
   },
   "source": [
    "### Saving simple model\n",
    "Creating model folder + saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-Xd8-5YVVxrR"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "if not os.path.isdir(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "if not os.path.isdir(\"model/simple_solution\"):\n",
    "        os.mkdir(\"model/simple_solution\")\n",
    "        \n",
    "with open('model/simple_solution/simple_model.pkl','wb') as f:\n",
    "    pickle.dump(logistic,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset with correct features:\n",
    "\n",
    "# Save as model_name+(X/y)+(tr/va/te) (depending if its dataset or lavels and what type they are)\n",
    "\n",
    "with open('model/simple_solution/simple_model_X_tr.pkl','wb') as f:\n",
    "    pickle.dump(X_tr_q1q2,f)  \n",
    "with open('model/simple_solution/simple_model_X_va.pkl','wb') as f:\n",
    "    pickle.dump(X_va_q1q2,f)   \n",
    "with open('model/simple_solution/simple_model_X_te.pkl','wb') as f:\n",
    "    pickle.dump(X_te_q1q2,f)\n",
    "with open('model/simple_solution/simple_model_y_tr.pkl','wb') as f:\n",
    "    pickle.dump(y_tr,f)\n",
    "with open('model/simple_solution/simple_model_y_va.pkl','wb') as f:\n",
    "    pickle.dump(y_va,f)\n",
    "with open('model/simple_solution/simple_model_y_te.pkl','wb') as f:\n",
    "    pickle.dump(y_te,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HOWSSEk4R1P"
   },
   "source": [
    "# Improved Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Claening\n",
    "### Feature Selection (try different models with different features)\n",
    "### Incorporate embeddings (word2vec, TF-IDF, ...) + train more models\n",
    "### Pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25le_Ovw4WYo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
